Yes — this is *exactly* what DataForSEO OnPage is built for, and you’re sitting on 80% of the plumbing already.

Let’s turn that **Pages** screen into:

1. A **per-URL Technical Audit page** (deep dive).
2. A **central Technical Issues / Site Audit dashboard**.
3. A **technical score engine** that feeds your existing Health + Tech Risk + Recommendations.

I’ll break it into:

* **A. What data to pull from OnPage (concrete fields + endpoints)**
* **B. New data model (tables + relationships)**
* **C. UX: per-page audit view + global tech dashboard**
* **D. How it flows into Recommendations + Tech Score**
* **E. Implementation phases (so dev doesn’t die).**

---

## A. What to pull from DataForSEO OnPage

OnPage gives you way more than status codes and titles; you can drive your entire “Technical” pillar from it. Key pieces:

### 1. Core endpoints to use

From DataForSEO v3 OnPage API:

* `on_page/task_post` – create crawl task for domain / section.
* `on_page/tasks_ready` – see which tasks have finished.
* `on_page/summary` – domain-level stats + **onpage_score** and counts of issues. ([DataForSEO][1])
* `on_page/pages` – per-page metrics, issues, meta, links, etc. ([DataForSEO][2])
* `on_page/non_indexable` – list of URLs blocked by robots/headers/meta. ([docs.dataforseo.com][3])
* `on_page/lighthouse` (optional v2) – Core Web Vitals & performance metrics.
* If you want, `on_page/resources` / `on_page/errors` for JS/CSS/HTML errors later.

### 2. Metrics that matter for your Tech Audit

From the OnPage score article + 120 metrics list: ([DataForSEO][1])

**Critical issues:**

* `high_loading_time`
* `broken_links`
* `broken_resources`
* `redirect_loop`
* `canonical_to_broken`
* `canonical_to_redirect`
* `canonical_chain`
* `recursive_canonical`
* `duplicate_content`
* `links_relation_conflict`
* `is_http`

**Important issues / warnings:**

* `no_title`, `duplicate_title`, `duplicate_title_tag`
* `no_description`, `duplicate_description`, `irrelevant_title`, `irrelevant_description`
* `no_h1_tags`
* `no_image_alt`
* `large_page_size`
* `is_orphan_page`
* `seo_friendly_url` (bad when false)
* `deprecated_html_tags`
* `low_readability_rate`, `high_character_count`, `low_character_count`
* `lorem_ipsum`
* `no_doctype`
* etc.

**Page-level metrics:**

* `onpage_score` (0–100 per page)
* HTTP status code
* indexability flags (robots, meta robots, x-robots, non_indexable endpoint)
* canonical URL
* word count, content rate, readability
* internal/external/broken link counts
* Core Web Vitals (from Lighthouse): LCP, FID, CLS, TBT, etc.

This is enough to build:

* A **Tech Score** for each URL (and roll it up).
* A **checklist of issues per page**.
* A **global breakdown by issue type**.

---

## B. Data Model: How to store this cleanly

Right now Pages tab has URL, Avg Position, Top 10, Backlinks, Link Velocity, Health, Tech Risk, Content Gap. You’ll bolt OnPage on top of that instead of hacking it into a single JSON blob.

### 1. `page_audits` table (one row per page per crawl)

```text
page_audits
- id (PK)
- page_id (FK -> pages.id)
- crawl_id (FK -> crawls.id or onpage_task_id)
- onpage_score (0–100)
- status_code (INT)
- indexable (BOOL)
- canonical_url (TEXT)
- word_count (INT)
- readability_score (FLOAT)
- page_size_kb (FLOAT)
- lcp_ms (INT, nullable)
- cls (FLOAT, nullable)
- tbt_ms (INT, nullable)
- first_input_delay_ms (INT, nullable)
- internal_links_count (INT)
- external_links_count (INT)
- broken_links_count (INT)
- images_without_alt (INT)
- created_at (TIMESTAMP)
```

### 2. `page_issues` table (normalized issue list)

```text
page_issues
- id (PK)
- page_audit_id (FK -> page_audits.id)
- issue_code (TEXT)       -- e.g. 'broken_links', 'no_title'
- severity (ENUM: 'critical' | 'warning' | 'info')
- category (ENUM: 'indexability' | 'content' | 'links' | 'performance' | 'html' | 'other')
- occurrences (INT)       -- how many instances on the page
- sample (JSONB)          -- sample links/HTML, text from API
```

You populate this by mapping DataForSEO flags:

* if `broken_links > 0` → issue_code = `broken_links`, severity = `critical`, category = `links`.
* if `no_h1_tags = 1` → issue_code = `no_h1_tags`, severity = `warning`, category = `content`.
* etc., using the critical/important weights from their docs. ([DataForSEO][4])

### 3. `tech_crawls` table (OnPage task tracking)

```text
tech_crawls
- id (PK)
- project_id
- onpage_task_id (string from DataForSEO)
- started_at
- finished_at
- pages_crawled
- status ('queued' | 'running' | 'completed' | 'failed')
```

Every time you click “Technical Crawl” or a scheduled crawl runs:

* create a `tech_crawls` row,
* create OnPage task,
* poll `tasks_ready`,
* ingest `summary`, `pages`, `non_indexable`, `lighthouse`,
* fill `page_audits` and `page_issues`.

Now you can:

* show “Last technical crawl: 3 days ago”
* compare “current vs previous audit” if you want later.

---

## C. UX: Per-Page Technical Audit + Global Tech Dashboard

### 1. Per-URL Technical Audit Page

From the Pages grid (what you screenshotted), add:

* A “View Audit” icon on each row → `/pages/:id/technical`.

**Layout for `/pages/:id/technical`**

**Header:**

* URL (clickable)
* OnPage Score badge (0–100 with color)
* Tech Risk label: Low / Medium / High
* Last crawled date
* Buttons:

  * “Re-run audit for this URL”
  * “Open in browser”

**Section 1 – Indexability & HTTP**

* Indexable: Yes/No (with reason from non_indexable)
* Status code
* Canonical URL (and whether it’s valid)
* Robots meta / x-robots
* Click depth
* Orphan page? (yes/no)

**Section 2 – Performance & Core Web Vitals**

* LCP, FID, CLS, TBT (from Lighthouse, where available)
* High loading time flag
* Page size (KB/MB)
* Cachable? (yes/no)

**Section 3 – Content & Structure**

* Title text + length + “too short/too long/duplicate” warnings.
* Meta description + length + relevance flag.
* H1 present? H2/H3 breakdown.
* Word count + readability score.
* Placeholder/lorem ipsum issues.

**Section 4 – Links**

* Internal links count
* External links count
* Broken links (with a small table of top offenders: href + anchor)
* Mixed follow/nofollow conflict flag (links_relation_conflict).

**Section 5 – Issues List**

Table or accordions grouped by severity:

* Critical Issues
* Warnings
* Informational

Each row:

* Issue label (e.g. “Broken links”)
* `issue_code`
* Severity dot
* Occurrences
* Short explanation
* CTA: “Create Recommendation” (auto-creates a task in Recommendations board for this page + issue)

Everything in this view is served from your own DB (`page_audits` and `page_issues`), not live from API, so you’re not burning credits on every click.

---

### 2. Global “Technical Audit” / Site Issues Dashboard

This is essentially the “Site Audit / Technical Issues Dashboard” we talked about, powered by the new tables.

Add a new page under **Analytics** or a new section under Pages, e.g.:

> Analytics → **Site Audit**

**Top cards:**

* Pages crawled in last audit
* Pages with *any* critical issue
* Avg OnPage Score
* Non-indexable pages
* Core Web Vitals failing pages

**Issue breakdown:**

* Bar/stacked chart: top issue categories by affected pages

  * Indexability, Status Codes, Canonical, Content, Links, Performance, HTML.
* Table of “Top issues”:

  * Issue name (Broken links)
  * Severity
  * # Pages affected
  * Trend vs previous crawl (▲/▼)

Clicking a row filters the Pages list below.

**Pages grid (technical view):**

Very similar to your existing Pages table, but enriched:

Columns:

* URL
* OnPage Score
* Tech Risk (Low/Med/High)
* Status code
* Indexable?
* Critical issues count
* Warnings count
* Broken links count
* Images without alt
* Last audit date
* “View Audit” button

Filters:

* Tech Risk
* Issue category
* Status code
* Indexable / non-indexable
* Core vs non-core page

Export:

* “Export issues to CSV/XLSX” → one row per page-issue combination, perfect for dev backlog.

This becomes Mahnoor’s & dev’s **default technical view**.

---

## D. Feed it back into Recommendations + Tech Score

This is where it stops being “nice analytics” and becomes an **ops engine**.

### 1. Auto-generate Recommendations from issues

When ingesting `page_issues`, you run a rules engine:

**Pseudo-logic:**

* For each new `page_issue` where:

  * severity in (`critical`, `warning`)
  * and not already open for this page/issue_code:

Create a `recommendations` row:

```text
recommendations
- id
- project_id
- page_id
- keyword_id (nullable)
- issue_code
- type = 'technical'
- severity (map from issue)
- status = 'open'
- title = "Fix broken links on {URL}"
- description = "OnPage API detected {occurrences} broken links on this URL during crawl {crawl_date}."
- owner (nullable; to be set by lead)
- due_date (nullable)
- created_from = 'onpage_api'
- created_at
```

Then:

* These show up in `/recommendations` under **Type: Technical**.
* Clicking them deep-links to the per-page audit.

You can also:

* Group recommendations at “issue + project” level:

  * e.g., “Add alt text to images on 23 pages” → 1 global recommendation, with a link to filtered list, instead of 23 duplicates (optional v2).

### 2. Compute “Technical Score” from OnPage data

You already show:

* Health
* Tech Risk
* Content Gap

Now wire them properly:

**Per-page Tech Score:**

* Start with DataForSEO `onpage_score` (0–100). ([DataForSEO][1])
* Optionally adjust with your own weighting:

  * If non-indexable or 5xx → force Tech Score = 0.
  * If high_loading_time or many broken_links → cap max score.

**Tech Risk label:**

* High Risk if:

  * onpage_score < 60 OR any critical issues exist.
* Medium Risk if:

  * onpage_score 60–80 AND only warnings.
* Low Risk if:

  * onpage_score > 80 AND no critical issues.

**Roll-up into Domain “Technical” component:**

* Your Dashboard health breakdown already has a “Technical” slice.
* Replace any placeholder logic with:

  * average of `onpage_score` across all **indexable core pages** (or weighted by traffic later when you integrate GSC).

Now:

* The overall SEO Health Score card changes **because of actual OnPage data**, not arbitrary numbers.
* Tech Risk in the Pages grid is mathematically consistent with OnPage API weights.

---

## E. Implementation Phasing (so it’s shippable, not a moonshot)

### Phase 1 – Plumbing & Minimal UX (2–3 sprints)

* Implement:

  * `tech_crawls`, `page_audits`, `page_issues` tables.
  * OnPage crawl pipeline (create task → poll → ingest summary + pages).
  * Map subset of key issue codes into `page_issues`.
  * Store per-page `onpage_score` + a few core metrics (status, indexable, broken_links, no_title, no_description, no_h1_tags, no_image_alt, high_loading_time).

* UI:

  * Add Tech columns to existing Pages grid:

    * OnPage Score
    * Tech Risk
    * Critical issues count
  * Show “Last tech crawl” timestamp somewhere in Pages header.

**Result:** You’re already computing tech risk from real data.

---

### Phase 2 – Per-Page Audit + Recommendations Hook (2 sprints)

* Build `/pages/:id/technical` view with:

  * Header (score, status, indexable).
  * Sections for indexability, performance, content, links, issues.
* Implement recommendation auto-generation:

  * On ingest, create technical recommendations from critical/warning `page_issues`.
  * Add deep links between Recommendations → Page Audit.

**Result:** dev/content team has one place to debug each URL.

---

### Phase 3 – Global Site Audit Dashboard (1–2 sprints)

* New **Site Audit** page:

  * Top cards, issue breakdown chart, tables.
  * Filters + export.
* Tune Tech Score and Dashboard health breakdown to use OnPage data.

**Result:** Mahnoor runs her 12–1 PM “technical sweep” from this screen instead of several tools.

---

### Phase 4 – Lighthouse & Advanced Metrics (optional)

* Add Lighthouse endpoint to audits to populate Core Web Vitals.
* Extend issues mapping for more nuanced performance/usability issues.
* Add trend charts:

  * “OnPage score over last 3 crawls”
  * “# of pages with broken links over time”

---

If you want, next step I can:

* Draft the **exact DB schema + example JSON mapping** from a typical OnPage `summary` + `pages` response into `page_audits` and `page_issues`, or
* Write a **Replit agent prompt just for “OnPage ingestion + Technical Audit views”** that your dev can drop in as the next module.

[1]: https://dataforseo.com/update/introducing-onpage-seo-score?utm_source=chatgpt.com "Introducing SEO Score in OnPage API | DataForSEO Updates"
[2]: https://dataforseo.com/apis/on-page-api?utm_source=chatgpt.com "SEO Audit Data and Website Crawling Tool – On-Page API by DataForSEO"
[3]: https://docs.dataforseo.com/v3/on_page-non_indexable/?utm_source=chatgpt.com "on_page/non_indexable – DataForSEO API v.3"
[4]: https://dataforseo.com/blog/120-onpage-api-metrics-explained?utm_source=chatgpt.com "120 OnPage API Metrics Explained – DataForSEO"
